{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetic Retinopathy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzQjtDrs3flT/j4kaN8goy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitishmagendran/ESPSubmissions/blob/main/Diabetic_Retinopathy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf1gxOxUrTpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98ea4546-d4d6-499d-ddae-f8ac874146d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_VECgstcqM"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q57o4JsEtkwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d47b9513-a63b-43ac-e94e-b1fc250de883"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnRzAttWus0O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Bmv8n6wM_c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NocgFIy_wcdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "900ddaee-7031-4fa0-dda0-f17e50bd6033"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id_code  diagnosis\n",
            "0  000c1434d8d7          2\n",
            "1  001639a390f0          4\n",
            "2  0024cdab0c1e          1\n",
            "3  002c21358ce6          0\n",
            "4  005b95c28852          0\n",
            "5  0083ee8054ee          4\n",
            "6  0097f532ac9f          0\n",
            "7  00a8624548a9          2\n",
            "8  00b74780d31d          2\n",
            "9  00cb6555d108          1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48NVkAFSwhgS"
      },
      "source": [
        "\n",
        "train_dir = './gdrive/My Drive/Datasets/fundus/resized_train_cropped/Train'\n",
        "valid_dir = './gdrive/My Drive/Datasets/fundus/resized_train_cropped/Validate'\n",
        "test_dir = './gdrive/My Drive/Datasets/fundus/resized_train_cropped/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j4kxdbEfXnR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytAAh_4OXQXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "71d0e2f7-83fa-47a4-efbc-a8b66e3d4e88"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   fill_mode = 'nearest')\n",
        "train_generator = train_datagen.flow_from_directory( train_dir,\n",
        "                                                    target_size = (299,299),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'sparse')\n",
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4053 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'level_0': 0, 'level_1': 1, 'level_2': 2, 'level_3': 3, 'level_4': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvSUsfUUtgVJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynckcVzUshoj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z053jfJlsf7n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wyfZgs2sbu3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JaqgkmZfso4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f397be8a-4ad6-49aa-ce92-bd7d4b310675"
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = val_datagen.flow_from_directory(valid_dir,\n",
        "                                                       target_size = (299,299),\n",
        "                                                       batch_size = 20,\n",
        "                                                       class_mode = 'sparse')\n",
        "validation_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4068 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'level_0': 0, 'level_1': 1, 'level_2': 2, 'level_3': 3, 'level_4': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZyuwQNvR5U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_HQOWAGgeeA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0c5f071-bae9-4731-b91a-c50cb54f733a"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "conv_base = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikoxq_Xmg97z"
      },
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'conv2d_93':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cz_oUduiAzV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e872d42b-139e-4cc2-c1c0-760060d16ebb"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256,activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(5,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               33554688  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 55,358,757\n",
            "Trainable params: 33,949,701\n",
            "Non-trainable params: 21,409,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDIpND9GjsJo"
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate =1e-5),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoPNaVYlknSH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33693018-1ae4-4810-efa6-d60757ae9719"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=10,\n",
        "                              epochs = 200,\n",
        "                              validation_data = validation_generator,\n",
        "                              validation_steps = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "10/10 [==============================] - 81s 8s/step - loss: 1.4728 - accuracy: 0.3575 - val_loss: 1.3601 - val_accuracy: 0.3875\n",
            "Epoch 2/200\n",
            "10/10 [==============================] - 82s 8s/step - loss: 1.4644 - accuracy: 0.3200 - val_loss: 1.3468 - val_accuracy: 0.4062\n",
            "Epoch 3/200\n",
            "10/10 [==============================] - 82s 8s/step - loss: 1.3650 - accuracy: 0.4100 - val_loss: 1.4633 - val_accuracy: 0.3378\n",
            "Epoch 4/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4237 - accuracy: 0.3550 - val_loss: 1.4365 - val_accuracy: 0.3500\n",
            "Epoch 5/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.4260 - accuracy: 0.3300 - val_loss: 1.4155 - val_accuracy: 0.3500\n",
            "Epoch 6/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3912 - accuracy: 0.3700 - val_loss: 1.3518 - val_accuracy: 0.3938\n",
            "Epoch 7/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3890 - accuracy: 0.3550 - val_loss: 1.4031 - val_accuracy: 0.3812\n",
            "Epoch 8/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3959 - accuracy: 0.3500 - val_loss: 1.3682 - val_accuracy: 0.3812\n",
            "Epoch 9/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.5721 - accuracy: 0.2650 - val_loss: 1.3214 - val_accuracy: 0.4187\n",
            "Epoch 10/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4547 - accuracy: 0.3400 - val_loss: 1.3439 - val_accuracy: 0.3688\n",
            "Epoch 11/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4054 - accuracy: 0.3600 - val_loss: 1.3926 - val_accuracy: 0.3375\n",
            "Epoch 12/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3434 - accuracy: 0.4100 - val_loss: 1.3422 - val_accuracy: 0.3812\n",
            "Epoch 13/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3857 - accuracy: 0.3850 - val_loss: 1.3594 - val_accuracy: 0.3688\n",
            "Epoch 14/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3726 - accuracy: 0.3900 - val_loss: 1.3084 - val_accuracy: 0.4500\n",
            "Epoch 15/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3666 - accuracy: 0.3750 - val_loss: 1.3485 - val_accuracy: 0.4062\n",
            "Epoch 16/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3908 - accuracy: 0.3750 - val_loss: 1.2742 - val_accuracy: 0.4375\n",
            "Epoch 17/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4205 - accuracy: 0.3550 - val_loss: 1.3019 - val_accuracy: 0.4375\n",
            "Epoch 18/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3846 - accuracy: 0.3400 - val_loss: 1.3313 - val_accuracy: 0.4000\n",
            "Epoch 19/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3333 - accuracy: 0.3700 - val_loss: 1.4108 - val_accuracy: 0.4125\n",
            "Epoch 20/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3832 - accuracy: 0.3200 - val_loss: 1.2445 - val_accuracy: 0.4500\n",
            "Epoch 21/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.4458 - accuracy: 0.3627 - val_loss: 1.2856 - val_accuracy: 0.4250\n",
            "Epoch 22/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3281 - accuracy: 0.4500 - val_loss: 1.3611 - val_accuracy: 0.3688\n",
            "Epoch 23/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3191 - accuracy: 0.4850 - val_loss: 1.3078 - val_accuracy: 0.4187\n",
            "Epoch 24/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3274 - accuracy: 0.4000 - val_loss: 1.3031 - val_accuracy: 0.4375\n",
            "Epoch 25/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3255 - accuracy: 0.4150 - val_loss: 1.2597 - val_accuracy: 0.4688\n",
            "Epoch 26/200\n",
            "10/10 [==============================] - 76s 8s/step - loss: 1.3144 - accuracy: 0.3950 - val_loss: 1.4136 - val_accuracy: 0.3851\n",
            "Epoch 27/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4945 - accuracy: 0.3200 - val_loss: 1.3683 - val_accuracy: 0.3812\n",
            "Epoch 28/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3326 - accuracy: 0.4450 - val_loss: 1.3341 - val_accuracy: 0.4250\n",
            "Epoch 29/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3531 - accuracy: 0.3850 - val_loss: 1.3356 - val_accuracy: 0.3812\n",
            "Epoch 30/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4012 - accuracy: 0.3500 - val_loss: 1.3925 - val_accuracy: 0.3562\n",
            "Epoch 31/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3772 - accuracy: 0.4000 - val_loss: 1.3446 - val_accuracy: 0.3812\n",
            "Epoch 32/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2864 - accuracy: 0.4450 - val_loss: 1.2842 - val_accuracy: 0.4313\n",
            "Epoch 33/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3315 - accuracy: 0.3650 - val_loss: 1.2691 - val_accuracy: 0.4313\n",
            "Epoch 34/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3608 - accuracy: 0.4050 - val_loss: 1.2806 - val_accuracy: 0.4563\n",
            "Epoch 35/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3475 - accuracy: 0.3850 - val_loss: 1.3379 - val_accuracy: 0.4437\n",
            "Epoch 36/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3629 - accuracy: 0.3650 - val_loss: 1.2597 - val_accuracy: 0.4500\n",
            "Epoch 37/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4133 - accuracy: 0.3500 - val_loss: 1.2068 - val_accuracy: 0.4500\n",
            "Epoch 38/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3461 - accuracy: 0.3850 - val_loss: 1.3827 - val_accuracy: 0.4000\n",
            "Epoch 39/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4094 - accuracy: 0.4000 - val_loss: 1.2252 - val_accuracy: 0.4625\n",
            "Epoch 40/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3469 - accuracy: 0.3950 - val_loss: 1.2572 - val_accuracy: 0.4625\n",
            "Epoch 41/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.3909 - accuracy: 0.3523 - val_loss: 1.1977 - val_accuracy: 0.4750\n",
            "Epoch 42/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3879 - accuracy: 0.4200 - val_loss: 1.3820 - val_accuracy: 0.3688\n",
            "Epoch 43/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2949 - accuracy: 0.4100 - val_loss: 1.3161 - val_accuracy: 0.3625\n",
            "Epoch 44/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2573 - accuracy: 0.4650 - val_loss: 1.2404 - val_accuracy: 0.4437\n",
            "Epoch 45/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3617 - accuracy: 0.3900 - val_loss: 1.2684 - val_accuracy: 0.3688\n",
            "Epoch 46/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3625 - accuracy: 0.3650 - val_loss: 1.3634 - val_accuracy: 0.3812\n",
            "Epoch 47/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3349 - accuracy: 0.4050 - val_loss: 1.2588 - val_accuracy: 0.4437\n",
            "Epoch 48/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3938 - accuracy: 0.3600 - val_loss: 1.2404 - val_accuracy: 0.4812\n",
            "Epoch 49/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3262 - accuracy: 0.3850 - val_loss: 1.3240 - val_accuracy: 0.3688\n",
            "Epoch 50/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3293 - accuracy: 0.3850 - val_loss: 1.3256 - val_accuracy: 0.4187\n",
            "Epoch 51/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3432 - accuracy: 0.3850 - val_loss: 1.2415 - val_accuracy: 0.4437\n",
            "Epoch 52/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3144 - accuracy: 0.4100 - val_loss: 1.3104 - val_accuracy: 0.4250\n",
            "Epoch 53/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3154 - accuracy: 0.4100 - val_loss: 1.2675 - val_accuracy: 0.4875\n",
            "Epoch 54/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2141 - accuracy: 0.4600 - val_loss: 1.2353 - val_accuracy: 0.4437\n",
            "Epoch 55/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2595 - accuracy: 0.4300 - val_loss: 1.2281 - val_accuracy: 0.4375\n",
            "Epoch 56/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3674 - accuracy: 0.4000 - val_loss: 1.2763 - val_accuracy: 0.4250\n",
            "Epoch 57/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.4232 - accuracy: 0.3800 - val_loss: 1.3715 - val_accuracy: 0.4688\n",
            "Epoch 58/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3782 - accuracy: 0.3900 - val_loss: 1.3491 - val_accuracy: 0.3750\n",
            "Epoch 59/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3248 - accuracy: 0.4050 - val_loss: 1.3021 - val_accuracy: 0.4187\n",
            "Epoch 60/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3475 - accuracy: 0.3550 - val_loss: 1.2610 - val_accuracy: 0.4500\n",
            "Epoch 61/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2889 - accuracy: 0.4300 - val_loss: 1.1801 - val_accuracy: 0.4500\n",
            "Epoch 62/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2661 - accuracy: 0.4145 - val_loss: 1.2039 - val_accuracy: 0.4875\n",
            "Epoch 63/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3611 - accuracy: 0.4400 - val_loss: 1.2626 - val_accuracy: 0.4500\n",
            "Epoch 64/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3113 - accuracy: 0.4200 - val_loss: 1.1727 - val_accuracy: 0.5125\n",
            "Epoch 65/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2579 - accuracy: 0.4500 - val_loss: 1.3313 - val_accuracy: 0.4062\n",
            "Epoch 66/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3189 - accuracy: 0.4200 - val_loss: 1.1503 - val_accuracy: 0.5250\n",
            "Epoch 67/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2826 - accuracy: 0.4300 - val_loss: 1.3180 - val_accuracy: 0.3938\n",
            "Epoch 68/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2401 - accuracy: 0.4300 - val_loss: 1.2906 - val_accuracy: 0.4563\n",
            "Epoch 69/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3563 - accuracy: 0.4200 - val_loss: 1.3304 - val_accuracy: 0.4750\n",
            "Epoch 70/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3128 - accuracy: 0.4500 - val_loss: 1.3085 - val_accuracy: 0.3875\n",
            "Epoch 71/200\n",
            "10/10 [==============================] - 76s 8s/step - loss: 1.3174 - accuracy: 0.4150 - val_loss: 1.2723 - val_accuracy: 0.3784\n",
            "Epoch 72/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2691 - accuracy: 0.4350 - val_loss: 1.2660 - val_accuracy: 0.4750\n",
            "Epoch 73/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3527 - accuracy: 0.4000 - val_loss: 1.2206 - val_accuracy: 0.4313\n",
            "Epoch 74/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3498 - accuracy: 0.3550 - val_loss: 1.2264 - val_accuracy: 0.4500\n",
            "Epoch 75/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2743 - accuracy: 0.4450 - val_loss: 1.2264 - val_accuracy: 0.4375\n",
            "Epoch 76/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3764 - accuracy: 0.3950 - val_loss: 1.3207 - val_accuracy: 0.3875\n",
            "Epoch 77/200\n",
            "10/10 [==============================] - 81s 8s/step - loss: 1.3439 - accuracy: 0.3950 - val_loss: 1.2979 - val_accuracy: 0.4563\n",
            "Epoch 78/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2946 - accuracy: 0.4150 - val_loss: 1.2060 - val_accuracy: 0.4563\n",
            "Epoch 79/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2667 - accuracy: 0.4000 - val_loss: 1.1714 - val_accuracy: 0.5125\n",
            "Epoch 80/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3449 - accuracy: 0.4200 - val_loss: 1.2619 - val_accuracy: 0.4250\n",
            "Epoch 81/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3192 - accuracy: 0.4150 - val_loss: 1.3710 - val_accuracy: 0.4125\n",
            "Epoch 82/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.3884 - accuracy: 0.3523 - val_loss: 1.2563 - val_accuracy: 0.3750\n",
            "Epoch 83/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2899 - accuracy: 0.4000 - val_loss: 1.1616 - val_accuracy: 0.5250\n",
            "Epoch 84/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3482 - accuracy: 0.3750 - val_loss: 1.1613 - val_accuracy: 0.4750\n",
            "Epoch 85/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2784 - accuracy: 0.4300 - val_loss: 1.2539 - val_accuracy: 0.4563\n",
            "Epoch 86/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2294 - accuracy: 0.4250 - val_loss: 1.1956 - val_accuracy: 0.4812\n",
            "Epoch 87/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3500 - accuracy: 0.4550 - val_loss: 1.2269 - val_accuracy: 0.4625\n",
            "Epoch 88/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2653 - accuracy: 0.4450 - val_loss: 1.3282 - val_accuracy: 0.3938\n",
            "Epoch 89/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3262 - accuracy: 0.4250 - val_loss: 1.1995 - val_accuracy: 0.5000\n",
            "Epoch 90/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2326 - accuracy: 0.4450 - val_loss: 1.1787 - val_accuracy: 0.4688\n",
            "Epoch 91/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2979 - accuracy: 0.4250 - val_loss: 1.3577 - val_accuracy: 0.4375\n",
            "Epoch 92/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2962 - accuracy: 0.4000 - val_loss: 1.2296 - val_accuracy: 0.4625\n",
            "Epoch 93/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2492 - accuracy: 0.4250 - val_loss: 1.2305 - val_accuracy: 0.4375\n",
            "Epoch 94/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.2411 - accuracy: 0.4900 - val_loss: 1.2137 - val_accuracy: 0.4392\n",
            "Epoch 95/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1688 - accuracy: 0.5050 - val_loss: 1.2625 - val_accuracy: 0.4750\n",
            "Epoch 96/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3315 - accuracy: 0.4450 - val_loss: 1.2685 - val_accuracy: 0.4688\n",
            "Epoch 97/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3060 - accuracy: 0.4550 - val_loss: 1.2398 - val_accuracy: 0.4437\n",
            "Epoch 98/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2667 - accuracy: 0.4400 - val_loss: 1.3182 - val_accuracy: 0.3812\n",
            "Epoch 99/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2877 - accuracy: 0.4350 - val_loss: 1.1838 - val_accuracy: 0.4688\n",
            "Epoch 100/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3261 - accuracy: 0.4100 - val_loss: 1.2263 - val_accuracy: 0.4750\n",
            "Epoch 101/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3575 - accuracy: 0.3900 - val_loss: 1.2431 - val_accuracy: 0.4812\n",
            "Epoch 102/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.2641 - accuracy: 0.4456 - val_loss: 1.2040 - val_accuracy: 0.5063\n",
            "Epoch 103/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3784 - accuracy: 0.3500 - val_loss: 1.2168 - val_accuracy: 0.4563\n",
            "Epoch 104/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2407 - accuracy: 0.4200 - val_loss: 1.2400 - val_accuracy: 0.4187\n",
            "Epoch 105/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2769 - accuracy: 0.4100 - val_loss: 1.2662 - val_accuracy: 0.4125\n",
            "Epoch 106/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2322 - accuracy: 0.4550 - val_loss: 1.1894 - val_accuracy: 0.4625\n",
            "Epoch 107/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3213 - accuracy: 0.4350 - val_loss: 1.2457 - val_accuracy: 0.4750\n",
            "Epoch 108/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2479 - accuracy: 0.4450 - val_loss: 1.2488 - val_accuracy: 0.4875\n",
            "Epoch 109/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2547 - accuracy: 0.4600 - val_loss: 1.3155 - val_accuracy: 0.4187\n",
            "Epoch 110/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2329 - accuracy: 0.4850 - val_loss: 1.1549 - val_accuracy: 0.4875\n",
            "Epoch 111/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2291 - accuracy: 0.4250 - val_loss: 1.1864 - val_accuracy: 0.4688\n",
            "Epoch 112/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3211 - accuracy: 0.4000 - val_loss: 1.2563 - val_accuracy: 0.4375\n",
            "Epoch 113/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2157 - accuracy: 0.4550 - val_loss: 1.3139 - val_accuracy: 0.4812\n",
            "Epoch 114/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3270 - accuracy: 0.3950 - val_loss: 1.2447 - val_accuracy: 0.4688\n",
            "Epoch 115/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2912 - accuracy: 0.4150 - val_loss: 1.2197 - val_accuracy: 0.4563\n",
            "Epoch 116/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3028 - accuracy: 0.3800 - val_loss: 1.1624 - val_accuracy: 0.4688\n",
            "Epoch 117/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3075 - accuracy: 0.4050 - val_loss: 1.2136 - val_accuracy: 0.4750\n",
            "Epoch 118/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1983 - accuracy: 0.5050 - val_loss: 1.2157 - val_accuracy: 0.4625\n",
            "Epoch 119/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2990 - accuracy: 0.4500 - val_loss: 1.2823 - val_accuracy: 0.4437\n",
            "Epoch 120/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3412 - accuracy: 0.4200 - val_loss: 1.1836 - val_accuracy: 0.5000\n",
            "Epoch 121/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2417 - accuracy: 0.4550 - val_loss: 1.1324 - val_accuracy: 0.5188\n",
            "Epoch 122/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.1985 - accuracy: 0.4767 - val_loss: 1.1408 - val_accuracy: 0.5312\n",
            "Epoch 123/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3071 - accuracy: 0.4400 - val_loss: 1.3329 - val_accuracy: 0.4750\n",
            "Epoch 124/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3600 - accuracy: 0.4050 - val_loss: 1.2229 - val_accuracy: 0.4500\n",
            "Epoch 125/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2325 - accuracy: 0.5100 - val_loss: 1.1612 - val_accuracy: 0.5188\n",
            "Epoch 126/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1458 - accuracy: 0.5250 - val_loss: 1.2929 - val_accuracy: 0.3562\n",
            "Epoch 127/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2254 - accuracy: 0.4900 - val_loss: 1.2388 - val_accuracy: 0.4125\n",
            "Epoch 128/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2604 - accuracy: 0.4400 - val_loss: 1.1313 - val_accuracy: 0.5375\n",
            "Epoch 129/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1895 - accuracy: 0.4550 - val_loss: 1.0861 - val_accuracy: 0.4812\n",
            "Epoch 130/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2253 - accuracy: 0.4400 - val_loss: 1.2240 - val_accuracy: 0.4812\n",
            "Epoch 131/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2344 - accuracy: 0.4300 - val_loss: 1.2434 - val_accuracy: 0.4250\n",
            "Epoch 132/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2449 - accuracy: 0.4750 - val_loss: 1.1885 - val_accuracy: 0.5188\n",
            "Epoch 133/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3190 - accuracy: 0.3800 - val_loss: 1.0833 - val_accuracy: 0.5437\n",
            "Epoch 134/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2433 - accuracy: 0.4250 - val_loss: 1.0753 - val_accuracy: 0.5813\n",
            "Epoch 135/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3326 - accuracy: 0.4300 - val_loss: 1.2324 - val_accuracy: 0.5063\n",
            "Epoch 136/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2992 - accuracy: 0.3900 - val_loss: 1.2026 - val_accuracy: 0.4812\n",
            "Epoch 137/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3022 - accuracy: 0.4100 - val_loss: 1.2147 - val_accuracy: 0.4938\n",
            "Epoch 138/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3192 - accuracy: 0.4050 - val_loss: 1.2655 - val_accuracy: 0.4375\n",
            "Epoch 139/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.3373 - accuracy: 0.3850 - val_loss: 1.1602 - val_accuracy: 0.4662\n",
            "Epoch 140/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2226 - accuracy: 0.4750 - val_loss: 1.2136 - val_accuracy: 0.4500\n",
            "Epoch 141/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2845 - accuracy: 0.4900 - val_loss: 1.1773 - val_accuracy: 0.4375\n",
            "Epoch 142/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2746 - accuracy: 0.4150 - val_loss: 1.1391 - val_accuracy: 0.5188\n",
            "Epoch 143/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2128 - accuracy: 0.4611 - val_loss: 1.2224 - val_accuracy: 0.4812\n",
            "Epoch 144/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.1592 - accuracy: 0.5000 - val_loss: 1.1065 - val_accuracy: 0.4938\n",
            "Epoch 145/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2952 - accuracy: 0.4400 - val_loss: 1.1720 - val_accuracy: 0.5437\n",
            "Epoch 146/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2268 - accuracy: 0.4450 - val_loss: 1.1714 - val_accuracy: 0.4062\n",
            "Epoch 147/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2251 - accuracy: 0.4900 - val_loss: 1.2135 - val_accuracy: 0.4750\n",
            "Epoch 148/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2963 - accuracy: 0.4150 - val_loss: 1.2108 - val_accuracy: 0.4625\n",
            "Epoch 149/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2207 - accuracy: 0.5300 - val_loss: 1.2431 - val_accuracy: 0.4187\n",
            "Epoch 150/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2945 - accuracy: 0.4250 - val_loss: 1.2127 - val_accuracy: 0.4938\n",
            "Epoch 151/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2610 - accuracy: 0.4450 - val_loss: 1.2471 - val_accuracy: 0.4313\n",
            "Epoch 152/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3218 - accuracy: 0.4400 - val_loss: 1.1269 - val_accuracy: 0.4812\n",
            "Epoch 153/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2106 - accuracy: 0.4750 - val_loss: 1.1930 - val_accuracy: 0.4812\n",
            "Epoch 154/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2349 - accuracy: 0.4650 - val_loss: 1.2060 - val_accuracy: 0.4688\n",
            "Epoch 155/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.1662 - accuracy: 0.4750 - val_loss: 1.2214 - val_accuracy: 0.4750\n",
            "Epoch 156/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2208 - accuracy: 0.4550 - val_loss: 1.1260 - val_accuracy: 0.5188\n",
            "Epoch 157/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3365 - accuracy: 0.4450 - val_loss: 1.2505 - val_accuracy: 0.4688\n",
            "Epoch 158/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3227 - accuracy: 0.4200 - val_loss: 1.2047 - val_accuracy: 0.4750\n",
            "Epoch 159/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2571 - accuracy: 0.4550 - val_loss: 1.1082 - val_accuracy: 0.5562\n",
            "Epoch 160/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.3153 - accuracy: 0.4500 - val_loss: 1.2206 - val_accuracy: 0.4625\n",
            "Epoch 161/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2054 - accuracy: 0.4900 - val_loss: 1.2304 - val_accuracy: 0.4625\n",
            "Epoch 162/200\n",
            "10/10 [==============================] - 77s 8s/step - loss: 1.2028 - accuracy: 0.4700 - val_loss: 1.2011 - val_accuracy: 0.4730\n",
            "Epoch 163/200\n",
            "10/10 [==============================] - 78s 8s/step - loss: 1.2611 - accuracy: 0.4715 - val_loss: 1.2281 - val_accuracy: 0.4500\n",
            "Epoch 164/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2619 - accuracy: 0.4750 - val_loss: 1.1784 - val_accuracy: 0.5125\n",
            "Epoch 165/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.3070 - accuracy: 0.4000 - val_loss: 1.2122 - val_accuracy: 0.4625\n",
            "Epoch 166/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2863 - accuracy: 0.4100 - val_loss: 1.1953 - val_accuracy: 0.4750\n",
            "Epoch 167/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2263 - accuracy: 0.4750 - val_loss: 1.2128 - val_accuracy: 0.5312\n",
            "Epoch 168/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2106 - accuracy: 0.4750 - val_loss: 1.1718 - val_accuracy: 0.4625\n",
            "Epoch 169/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2598 - accuracy: 0.4050 - val_loss: 1.2467 - val_accuracy: 0.4875\n",
            "Epoch 170/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2357 - accuracy: 0.4750 - val_loss: 1.2009 - val_accuracy: 0.4625\n",
            "Epoch 171/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2735 - accuracy: 0.4350 - val_loss: 1.1732 - val_accuracy: 0.5000\n",
            "Epoch 172/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2479 - accuracy: 0.4600 - val_loss: 1.2409 - val_accuracy: 0.4688\n",
            "Epoch 173/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2281 - accuracy: 0.4300 - val_loss: 1.1799 - val_accuracy: 0.4125\n",
            "Epoch 174/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.2611 - accuracy: 0.4100 - val_loss: 1.1363 - val_accuracy: 0.4812\n",
            "Epoch 175/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1778 - accuracy: 0.4500 - val_loss: 1.2229 - val_accuracy: 0.4812\n",
            "Epoch 176/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2624 - accuracy: 0.4500 - val_loss: 1.1037 - val_accuracy: 0.5125\n",
            "Epoch 177/200\n",
            "10/10 [==============================] - 79s 8s/step - loss: 1.1097 - accuracy: 0.5450 - val_loss: 1.0561 - val_accuracy: 0.5625\n",
            "Epoch 178/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2395 - accuracy: 0.4750 - val_loss: 1.1211 - val_accuracy: 0.5000\n",
            "Epoch 179/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.1958 - accuracy: 0.5000 - val_loss: 1.1677 - val_accuracy: 0.4750\n",
            "Epoch 180/200\n",
            "10/10 [==============================] - 80s 8s/step - loss: 1.2631 - accuracy: 0.4350 - val_loss: 1.2164 - val_accuracy: 0.4625\n",
            "Epoch 181/200\n",
            " 3/10 [========>.....................] - ETA: 23s - loss: 1.2548 - accuracy: 0.3667"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUuc0IQElCjq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e13e4b4a-1c4f-41a3-ec87-bd3078760e6c"
      },
      "source": [
        "model.save('retinopathy3.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs,acc,'r',label='Training Acc')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation Acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,loss,'r',label='Training Loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ketWsDOVpFtI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4c097525-6622-4c15-f772-97622cc90a9f"
      },
      "source": [
        "test_dir = './gdrive/My Drive/gaussian_filtered_images'\n",
        "test_datagen= ImageDataGenerator(rescale= 1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (299,299),\n",
        "    batch_size = 20,\n",
        "    class_mode = 'sparse')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator,steps = 50)\n",
        "print('Test Accuracy on images: ', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3662 images belonging to 5 classes.\n",
            "WARNING:tensorflow:From <ipython-input-28-40fe24148a0e>:9: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "Test Accuracy on images:  0.6830000281333923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OLjf_AlrMRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5677d9-f781-4888-8889-6cb58ef7146b"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "image_pred = image.load_img('./gdrive/My Drive/Datasets/fundus/resized_train_cropped/Validate/level_1/17_right.jpeg',target_size = (299,299))\n",
        "image_pred = image.img_to_array(image_pred)\n",
        "image_pred = np.expand_dims(image_pred, axis = 0)\n",
        "rest = model.predict(image_pred)\n",
        "print(rest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.8222024e-19 9.9999189e-01 8.1371463e-06 1.5497668e-18 9.8558336e-13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzo9lquQvqXz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhqmX7-tvLcf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZMytCyvAZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCqJ_JUuei9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kypCeqZAuTwd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDq61AEcrI1H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQzcdPBkLWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ry5xB9cjnjh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8jpCTdpivXS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYp-143h6db"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJMD_cugh0nV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I18kdlBRfoy2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyC4vdpXcIuE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1CGElJpb9Ot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_j2Jq6Yb4cc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2armVRwftCoe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}